{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f65f2a09",
   "metadata": {},
   "source": [
    "# ECG Signal Detection Inference & Classification\n",
    "First Train the GAE using training notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc44a815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Import Required Modules\n",
    "\n",
    "# Import from src package\n",
    "from src.models import EnhancedJointECGModel\n",
    "from src.data_loader import get_dataloaders, ECGDataset\n",
    "from src.graph_utils import build_knn_graph\n",
    "from src.inference import predict, evaluate_model\n",
    "\n",
    "# Standard libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, classification_report\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ All modules imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79f076e",
   "metadata": {},
   "source": [
    "## Configuration & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14d0ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "INPUT_LENGTH = 187\n",
    "LATENT_DIM = 128\n",
    "NUM_CLASSES = 5\n",
    "BATCH_SIZE = 512\n",
    "K_NEIGHBORS = 5\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# File paths\n",
    "MODEL_PATH = 'models/best_model.pth'  # Trained model\n",
    "TEST_DATA_PATH = 'examples/sample_ecgs.csv'  # Test data (change to your real data)\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Model path: {MODEL_PATH}\")\n",
    "print(f\"Test data: {TEST_DATA_PATH}\")\n",
    "\n",
    "# Load test data using src.data_loader\n",
    "try:\n",
    "    # For demo, we'll use the same data for train/val/test\n",
    "    # In practice, use separate test file\n",
    "    _, _, test_loader = get_dataloaders(\n",
    "        train_path=TEST_DATA_PATH,\n",
    "        test_path=TEST_DATA_PATH,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        val_split=0.0,  # No validation for inference\n",
    "        test_split=1.0   # All data as test\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Test data loaded successfully!\")\n",
    "    print(f\"Test batches: {len(test_loader)}\")\n",
    "    \n",
    "    # Get full dataset for detailed analysis\n",
    "    test_dataset = ECGDataset(TEST_DATA_PATH, transform=None)\n",
    "    X_test_full = test_dataset.data.values\n",
    "    y_test_full = test_dataset.labels.values\n",
    "    \n",
    "    print(f\"Full test set: {len(X_test_full)} samples\")\n",
    "    print(f\"Classes: {sorted(np.unique(y_test_full))}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Test data file not found. Please update TEST_DATA_PATH\")\n",
    "    print(\"For demo purposes, we'll create synthetic data\")\n",
    "    \n",
    "    # Create synthetic test data for demonstration\n",
    "    np.random.seed(42)\n",
    "    X_test_full = np.random.randn(1000, 187).astype(np.float32)\n",
    "    y_test_full = np.random.randint(0, 5, 1000)\n",
    "    \n",
    "    print(\"‚úÖ Synthetic test data created for demonstration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433fb1f0",
   "metadata": {},
   "source": [
    "## Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd68e686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model using src.models\n",
    "model = EnhancedJointECGModel(\n",
    "    input_length=INPUT_LENGTH,\n",
    "    latent_dim=LATENT_DIM,\n",
    "    num_classes=NUM_CLASSES\n",
    ").to(DEVICE)\n",
    "\n",
    "# Load trained weights\n",
    "try:\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "    model.eval()\n",
    "    print(\"‚úÖ Model loaded successfully!\")\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Model file not found at {MODEL_PATH}\")\n",
    "    print(\"Please train a model first or update MODEL_PATH\")\n",
    "    print(\"For demo, we'll use randomly initialized model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae747787",
   "metadata": {},
   "source": [
    "## Event Detection Functions\n",
    "\n",
    "These functions simulate event detection (since we don't have a trained U-Net).\n",
    "In production, you'd replace these with your trained event detection model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35011471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_event_detection(signals, window_size=40, threshold_factor=0.5):\n",
    "    \"\"\"\n",
    "    Simple peak-based event detection using amplitude thresholding.\n",
    "    \n",
    "    Args:\n",
    "        signals: Array of ECG signals (n_samples, n_timesteps)\n",
    "        window_size: Size of sliding window for local statistics\n",
    "        threshold_factor: Multiplier for threshold (mean + factor*std)\n",
    "    \n",
    "    Returns:\n",
    "        masks: Binary masks indicating detected events\n",
    "    \"\"\"\n",
    "    masks = []\n",
    "    \n",
    "    for signal in signals:\n",
    "        # Compute local statistics\n",
    "        local_mean = pd.Series(signal).rolling(window=window_size, center=True).mean()\n",
    "        local_std = pd.Series(signal).rolling(window=window_size, center=True).std()\n",
    "        \n",
    "        # Fill NaN values\n",
    "        local_mean = local_mean.fillna(method='bfill').fillna(method='ffill')\n",
    "        local_std = local_std.fillna(method='bfill').fillna(method='ffill')\n",
    "        \n",
    "        # Threshold: local_mean + threshold_factor * local_std\n",
    "        threshold = local_mean + threshold_factor * local_std\n",
    "        \n",
    "        # Detect events\n",
    "        mask = (signal > threshold).astype(int)\n",
    "        masks.append(mask)\n",
    "    \n",
    "    return np.array(masks)\n",
    "\n",
    "def extend_events_with_baseline(signals, masks, baseline_duration_ms=50, sampling_rate=360):\n",
    "    \"\"\"\n",
    "    Extend detected events with baseline context.\n",
    "    \n",
    "    Args:\n",
    "        signals: ECG signals\n",
    "        masks: Event masks\n",
    "        baseline_duration_ms: Baseline duration in milliseconds\n",
    "        sampling_rate: ECG sampling rate\n",
    "    \n",
    "    Returns:\n",
    "        segments: Extended segments\n",
    "        segment_info: Metadata about each segment\n",
    "    \"\"\"\n",
    "    baseline_samples = int(baseline_duration_ms * sampling_rate / 1000)\n",
    "    segments = []\n",
    "    segment_info = []\n",
    "    \n",
    "    for idx, (signal, mask) in enumerate(zip(signals, masks)):\n",
    "        event_indices = np.where(mask == 1)[0]\n",
    "        \n",
    "        if len(event_indices) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Group consecutive events\n",
    "        diff = np.diff(event_indices, prepend=0, append=len(signal))\n",
    "        group_starts = np.where(diff > 1)[0]\n",
    "        group_ends = np.where(diff > 1)[0][1:] - 1\n",
    "        if len(group_ends) < len(group_starts):\n",
    "            group_ends = np.append(group_ends, len(event_indices) - 1)\n",
    "        \n",
    "        for start_idx, end_idx in zip(group_starts, group_ends):\n",
    "            event_start = event_indices[start_idx]\n",
    "            event_end = event_indices[end_idx]\n",
    "            \n",
    "            # Extend with baseline\n",
    "            seg_start = max(0, event_start - baseline_samples)\n",
    "            seg_end = min(len(signal), event_end + baseline_samples)\n",
    "            \n",
    "            segment = signal[seg_start:seg_end]\n",
    "            segments.append(segment)\n",
    "            \n",
    "            segment_info.append({\n",
    "                'original_idx': idx,\n",
    "                'event_start': event_start,\n",
    "                'event_end': event_end,\n",
    "                'segment_start': seg_start,\n",
    "                'segment_end': seg_end,\n",
    "                'baseline_before': event_start - seg_start,\n",
    "                'baseline_after': seg_end - event_end\n",
    "            })\n",
    "    \n",
    "    return segments, segment_info\n",
    "\n",
    "def preprocess_segment(segment, target_length=187):\n",
    "    \"\"\"\n",
    "    Resample segment to target length using interpolation.\n",
    "    \n",
    "    Args:\n",
    "        segment: ECG segment\n",
    "        target_length: Desired length\n",
    "    \n",
    "    Returns:\n",
    "        Processed segment\n",
    "    \"\"\"\n",
    "    if len(segment) == target_length:\n",
    "        return segment\n",
    "    \n",
    "    # Simple interpolation\n",
    "    x_old = np.linspace(0, 1, len(segment))\n",
    "    x_new = np.linspace(0, 1, target_length)\n",
    "    \n",
    "    return np.interp(x_new, x_old, segment)\n",
    "\n",
    "print(\"‚úÖ Event detection functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdffdb74",
   "metadata": {},
   "source": [
    "## Model Inference Pipeline\n",
    "\n",
    "Process detected events through the trained GAE model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0f5570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event Detection on Test Data\n",
    "print(\"üîç Detecting events in test data...\")\n",
    "event_masks = simple_event_detection(X_test_full, threshold_factor=0.5)\n",
    "print(f\"Events detected in {np.sum(event_masks.sum(axis=1) > 0)}/{len(X_test_full)} signals\")\n",
    "\n",
    "# Extract segments with baseline\n",
    "print(\"üìè Extracting segments with baseline context...\")\n",
    "segments, segment_info = extend_events_with_baseline(\n",
    "    X_test_full, event_masks, \n",
    "    baseline_duration_ms=50\n",
    ")\n",
    "print(f\"Extracted {len(segments)} segments\")\n",
    "\n",
    "# Preprocess segments\n",
    "print(\"üîß Preprocessing segments...\")\n",
    "segments_processed = [preprocess_segment(seg, INPUT_LENGTH) for seg in segments]\n",
    "segments_tensor = torch.tensor(segments_processed, dtype=torch.float32).unsqueeze(1).to(DEVICE)\n",
    "\n",
    "print(f\"‚úÖ Preprocessing complete: {segments_tensor.shape[0]} segments of length {INPUT_LENGTH}\")\n",
    "\n",
    "# Model Inference using src.inference\n",
    "print(\"üöÄ Running model inference...\")\n",
    "\n",
    "# Extract CNN features\n",
    "with torch.no_grad():\n",
    "    cnn_features = model.ecg_encoder(segments_tensor)\n",
    "    print(f\"CNN features shape: {cnn_features.shape}\")\n",
    "\n",
    "# Build k-NN graph using src.graph_utils\n",
    "edge_index = build_knn_graph(cnn_features, k=K_NEIGHBORS)\n",
    "edge_index = edge_index.to(DEVICE)\n",
    "print(f\"Graph edges: {edge_index.shape[1]}\")\n",
    "\n",
    "# Run inference using src.inference.predict\n",
    "predictions, latent_representations, reconstructions = predict(\n",
    "    model=model,\n",
    "    data=segments_tensor,\n",
    "    edge_index=edge_index,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Inference complete!\")\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "print(f\"Latent shape: {latent_representations.shape}\")\n",
    "print(f\"Reconstructions shape: {reconstructions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23b4161",
   "metadata": {},
   "source": [
    "## Full Test Set Evaluation\n",
    "\n",
    "Evaluate the model on the entire test dataset using `src.inference.evaluate_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d047f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full test set evaluation using src.inference\n",
    "print(\"üìä Evaluating model on full test set...\")\n",
    "\n",
    "# Use the evaluate_model function from src\n",
    "metrics, visualizations = evaluate_model(\n",
    "    model=model,\n",
    "    test_loader=test_loader,\n",
    "    device=DEVICE,\n",
    "    k_neighbors=K_NEIGHBORS,\n",
    "    save_plots=True,\n",
    "    plot_prefix='detection_with_src'\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Evaluation complete!\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PERFORMANCE METRICS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Overall Accuracy: {metrics['accuracy']:.4f}\")\n",
    "print(f\"Macro F1-Score: {metrics['macro_f1']:.4f}\")\n",
    "print(f\"Weighted F1-Score: {metrics['weighted_f1']:.4f}\")\n",
    "\n",
    "print(\"\\nPer-Class Performance:\")\n",
    "for i, (prec, rec, f1) in enumerate(zip(metrics['precision'], metrics['recall'], metrics['f1'])):\n",
    "    print(f\"Class {i}: Precision={prec:.3f}, Recall={rec:.3f}, F1={f1:.3f}\")\n",
    "\n",
    "# Display confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(metrics['confusion_matrix'], annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[f'Class {i}' for i in range(NUM_CLASSES)],\n",
    "            yticklabels=[f'Class {i}' for i in range(NUM_CLASSES)])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (Full Test Set)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/confusion_matrix_detection_src.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Confusion matrix saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b3b6d8",
   "metadata": {},
   "source": [
    "## Advanced Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e70bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE Visualization of Latent Space\n",
    "print(\"üé® Computing t-SNE visualization...\")\n",
    "\n",
    "# Get true labels for segments (map back from segment_info)\n",
    "segment_labels = []\n",
    "for info in segment_info:\n",
    "    original_idx = info['original_idx']\n",
    "    segment_labels.append(y_test_full[original_idx])\n",
    "\n",
    "segment_labels = np.array(segment_labels)\n",
    "\n",
    "# t-SNE on latent representations\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, max_iter=1000)\n",
    "latent_2d = tsne.fit_transform(latent_representations)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Color by true class\n",
    "scatter = plt.scatter(latent_2d[:, 0], latent_2d[:, 1], \n",
    "                     c=segment_labels, cmap='viridis', alpha=0.6, s=30)\n",
    "\n",
    "# Color by predicted class\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter_pred = plt.scatter(latent_2d[:, 0], latent_2d[:, 1], \n",
    "                          c=predictions, cmap='plasma', alpha=0.6, s=30)\n",
    "\n",
    "plt.colorbar(scatter_pred, label='Predicted Class')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.title('Latent Space Visualization (Colored by Predictions)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/tsne_predictions_src.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ t-SNE visualizations saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68915068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Predictions Visualization\n",
    "print(\"üìã Analyzing sample predictions...\")\n",
    "\n",
    "# Get some examples from each class\n",
    "unique_classes = np.unique(segment_labels)\n",
    "fig, axes = plt.subplots(len(unique_classes), 4, figsize=(20, 5*len(unique_classes)))\n",
    "\n",
    "for i, class_idx in enumerate(unique_classes):\n",
    "    # Find samples of this class\n",
    "    class_mask = segment_labels == class_idx\n",
    "    class_indices = np.where(class_mask)[0]\n",
    "    \n",
    "    if len(class_indices) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Get correct and incorrect predictions\n",
    "    class_preds = predictions[class_indices]\n",
    "    correct_mask = class_preds == class_idx\n",
    "    incorrect_mask = class_preds != class_idx\n",
    "    \n",
    "    # Plot examples\n",
    "    examples_to_show = []\n",
    "    titles = []\n",
    "    \n",
    "    # Correct prediction\n",
    "    if np.any(correct_mask):\n",
    "        idx = class_indices[np.where(correct_mask)[0][0]]\n",
    "        examples_to_show.append(idx)\n",
    "        titles.append(f'Class {class_idx} (Correct)')\n",
    "    \n",
    "    # Incorrect prediction\n",
    "    if np.any(incorrect_mask):\n",
    "        idx = class_indices[np.where(incorrect_mask)[0][0]]\n",
    "        examples_to_show.append(idx)\n",
    "        titles.append(f'Class {class_idx} (Wrong‚Üí{int(predictions[idx])})')\n",
    "    \n",
    "    # Show up to 4 examples\n",
    "    for j, (idx, title) in enumerate(zip(examples_to_show, titles)):\n",
    "        if j >= 4:\n",
    "            break\n",
    "            \n",
    "        ax = axes[i, j] if len(unique_classes) > 1 else axes[j]\n",
    "        \n",
    "        # Original segment\n",
    "        ax.plot(segments_processed[idx], 'b-', alpha=0.7, label='Original')\n",
    "        \n",
    "        # Reconstruction\n",
    "        ax.plot(reconstructions[idx], 'r--', alpha=0.7, label='Reconstructed')\n",
    "        \n",
    "        ax.set_title(f'{title}\\nMSE: {np.mean((segments_processed[idx] - reconstructions[idx])**2):.4f}')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/sample_predictions_src.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Sample predictions visualization saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc3908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curves for Multi-Class\n",
    "print(\"üìà Computing ROC curves...\")\n",
    "\n",
    "# Binarize labels for multi-class ROC\n",
    "y_true_bin = label_binarize(segment_labels, classes=range(NUM_CLASSES))\n",
    "y_pred_prob = torch.softmax(torch.tensor(logits_all), dim=1).numpy()\n",
    "\n",
    "# Compute ROC curve for each class\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "colors = ['blue', 'red', 'green', 'orange', 'purple']\n",
    "for i in range(NUM_CLASSES):\n",
    "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_prob[:, i])\n",
    "    auc_score = roc_auc_score(y_true_bin[:, i], y_pred_prob[:, i])\n",
    "    \n",
    "    plt.plot(fpr, tpr, color=colors[i], \n",
    "             label=f'Class {i} (AUC = {auc_score:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves (Multi-Class, One-vs-Rest)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/roc_curves_src.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ ROC curves saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563afe99",
   "metadata": {},
   "source": [
    "## Interactive Prediction Viewer\n",
    "\n",
    "Browse individual predictions with an interactive interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983ce22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractiveECGViewer:\n",
    "    def __init__(self, segments, reconstructions, predictions, true_labels, segment_info):\n",
    "        self.segments = segments\n",
    "        self.reconstructions = reconstructions\n",
    "        self.predictions = predictions\n",
    "        self.true_labels = true_labels\n",
    "        self.segment_info = segment_info\n",
    "        \n",
    "        self.current_idx = 0\n",
    "        \n",
    "        # Create widgets\n",
    "        self.idx_slider = widgets.IntSlider(\n",
    "            value=0, min=0, max=len(segments)-1, step=1,\n",
    "            description='Sample:', continuous_update=False\n",
    "        )\n",
    "        \n",
    "        self.prev_button = widgets.Button(description='Previous')\n",
    "        self.next_button = widgets.Button(description='Next')\n",
    "        self.random_button = widgets.Button(description='Random')\n",
    "        \n",
    "        self.true_class_filter = widgets.Dropdown(\n",
    "            options=[('All', -1)] + [(f'Class {i}', i) for i in range(NUM_CLASSES)],\n",
    "            value=-1, description='True Class:'\n",
    "        )\n",
    "        \n",
    "        self.pred_class_filter = widgets.Dropdown(\n",
    "            options=[('All', -1)] + [(f'Class {i}', i) for i in range(NUM_CLASSES)],\n",
    "            value=-1, description='Pred Class:'\n",
    "        )\n",
    "        \n",
    "        self.status_filter = widgets.Dropdown(\n",
    "            options=[('All', -1), ('Correct', 1), ('Incorrect', 0)],\n",
    "            value=-1, description='Status:'\n",
    "        )\n",
    "        \n",
    "        # Connect callbacks\n",
    "        self.idx_slider.observe(self.update_display, names='value')\n",
    "        self.prev_button.on_click(self.prev_sample)\n",
    "        self.next_button.on_click(self.next_sample)\n",
    "        self.random_button.on_click(self.random_sample)\n",
    "        self.true_class_filter.observe(self.filter_samples, names='value')\n",
    "        self.pred_class_filter.observe(self.filter_samples, names='value')\n",
    "        self.status_filter.observe(self.filter_samples, names='value')\n",
    "        \n",
    "        # Filtered indices\n",
    "        self.filtered_indices = list(range(len(segments)))\n",
    "        \n",
    "        # Output area\n",
    "        self.output = widgets.Output()\n",
    "    \n",
    "    def filter_samples(self, change):\n",
    "        \"\"\"Filter samples based on criteria\"\"\"\n",
    "        true_filter = self.true_class_filter.value\n",
    "        pred_filter = self.pred_class_filter.value\n",
    "        status_filter = self.status_filter.value\n",
    "        \n",
    "        indices = []\n",
    "        for i in range(len(self.segments)):\n",
    "            true_class = self.true_labels[i]\n",
    "            pred_class = self.predictions[i]\n",
    "            is_correct = (true_class == pred_class)\n",
    "            \n",
    "            if true_filter != -1 and true_class != true_filter:\n",
    "                continue\n",
    "            if pred_filter != -1 and pred_class != pred_filter:\n",
    "                continue\n",
    "            if status_filter != -1 and is_correct != bool(status_filter):\n",
    "                continue\n",
    "                \n",
    "            indices.append(i)\n",
    "        \n",
    "        self.filtered_indices = indices\n",
    "        if self.current_idx >= len(self.filtered_indices):\n",
    "            self.current_idx = 0\n",
    "        \n",
    "        self.idx_slider.max = len(self.filtered_indices) - 1\n",
    "        self.idx_slider.value = min(self.current_idx, len(self.filtered_indices) - 1)\n",
    "        \n",
    "        self.update_display(None)\n",
    "    \n",
    "    def prev_sample(self, b):\n",
    "        if len(self.filtered_indices) > 0:\n",
    "            self.current_idx = (self.current_idx - 1) % len(self.filtered_indices)\n",
    "            self.idx_slider.value = self.current_idx\n",
    "    \n",
    "    def next_sample(self, b):\n",
    "        if len(self.filtered_indices) > 0:\n",
    "            self.current_idx = (self.current_idx + 1) % len(self.filtered_indices)\n",
    "            self.idx_slider.value = self.current_idx\n",
    "    \n",
    "    def random_sample(self, b):\n",
    "        if len(self.filtered_indices) > 0:\n",
    "            self.current_idx = np.random.randint(0, len(self.filtered_indices))\n",
    "            self.idx_slider.value = self.current_idx\n",
    "    \n",
    "    def update_display(self, change):\n",
    "        with self.output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            if len(self.filtered_indices) == 0:\n",
    "                print(\"No samples match the current filters.\")\n",
    "                return\n",
    "            \n",
    "            idx = self.filtered_indices[self.current_idx]\n",
    "            \n",
    "            # Get data\n",
    "            original = self.segments[idx]\n",
    "            reconstructed = self.reconstructions[idx]\n",
    "            true_class = self.true_labels[idx]\n",
    "            pred_class = self.predictions[idx]\n",
    "            info = self.segment_info[idx]\n",
    "            \n",
    "            # Create plot\n",
    "            fig = make_subplots(\n",
    "                rows=2, cols=1,\n",
    "                subplot_titles=('ECG Signal', 'Reconstruction Error'),\n",
    "                shared_xaxes=True\n",
    "            )\n",
    "            \n",
    "            # Original vs Reconstructed\n",
    "            fig.add_trace(\n",
    "                go.Scatter(y=original, mode='lines', name='Original', \n",
    "                          line=dict(color='blue')),\n",
    "                row=1, col=1\n",
    "            )\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Scatter(y=reconstructed, mode='lines', name='Reconstructed',\n",
    "                          line=dict(color='red', dash='dash')),\n",
    "                row=1, col=1\n",
    "            )\n",
    "            \n",
    "            # Reconstruction error\n",
    "            error = original - reconstructed\n",
    "            fig.add_trace(\n",
    "                go.Scatter(y=error, mode='lines', name='Error',\n",
    "                          line=dict(color='green')),\n",
    "                row=2, col=1\n",
    "            )\n",
    "            \n",
    "            fig.update_layout(height=600, title_text=f'Sample {idx} (Filtered Index {self.current_idx})')\n",
    "            \n",
    "            # Print metadata\n",
    "            print(f\"Sample {idx} (showing {self.current_idx+1}/{len(self.filtered_indices)} filtered)\")\n",
    "            print(f\"True Class: {true_class}, Predicted: {pred_class}\")\n",
    "            print(f\"Correct: {'‚úÖ' if true_class == pred_class else '‚ùå'}\")\n",
    "            print(f\"MSE: {np.mean(error**2):.6f}\")\n",
    "            print(f\"Correlation: {np.corrcoef(original, reconstructed)[0,1]:.4f}\")\n",
    "            print(f\"Event Info: Start={info['event_start']}, End={info['event_end']}\")\n",
    "            print(f\"Baseline: {info['baseline_before']}ms before, {info['baseline_after']}ms after\")\n",
    "            \n",
    "            fig.show()\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"Display the interactive interface\"\"\"\n",
    "        controls = widgets.HBox([\n",
    "            self.idx_slider,\n",
    "            widgets.VBox([self.prev_button, self.next_button, self.random_button])\n",
    "        ])\n",
    "        \n",
    "        filters = widgets.HBox([\n",
    "            self.true_class_filter,\n",
    "            self.pred_class_filter,\n",
    "            self.status_filter\n",
    "        ])\n",
    "        \n",
    "        display(widgets.VBox([controls, filters, self.output]))\n",
    "        \n",
    "        # Initial display\n",
    "        self.update_display(None)\n",
    "\n",
    "# Create and display viewer\n",
    "print(\"üéÆ Creating interactive ECG viewer...\")\n",
    "viewer = InteractiveECGViewer(\n",
    "    segments_processed,\n",
    "    reconstructions,\n",
    "    predictions,\n",
    "    segment_labels,\n",
    "    segment_info\n",
    ")\n",
    "\n",
    "viewer.display()\n",
    "\n",
    "print(\"‚úÖ Interactive viewer ready! Use the controls to explore predictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c295668",
   "metadata": {},
   "source": [
    "### Saved Files\n",
    "\n",
    "- `results/confusion_matrix_detection_src.png`\n",
    "- `results/tsne_predictions_src.png`\n",
    "- `results/sample_predictions_src.png`\n",
    "- `results/roc_curves_src.png`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae02021",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
